[audio]
sample_rate = 44100 
hop_length = 128
bins_per_octave = 48
num_octaves = 8

#Fast Griffin-Lim - number of iterations
n_iter = 64

[dataset]

datapath = C:\Users\il\Desktop\ImmersiveLab\machine-learning\datasets\Electroacoustic-Roads
cqt_dataset = npy
workspace = 
run_number = 0

[CVAE]
latent_dim = 8

num_dense_layers = 3
dense_units = 2048
dense_unit_divider = 2

num_conv_layers = 1
num_inital_filters = 32
kernel_size = 3

kl_beta = 5e-5
batch_norm = False
output_activation = relu

[training]
epochs = 500
learning_rate = 0.0001
batch_size = 256
buffer_size = 60000
buffer_size_dataset = True
continue_training = False

max_ckpts_to_keep = 2
checkpoint_epochs = 15
save_best_only = True
learning_schedule = False
early_patience_epoch = 100
early_delta = 1e-9

[notes]
additional_notes = one more conv. layer

mynotes = testing-example-audio-writting

[extra]
normalize_examples = False
example_length = 15
plot_model = True

description = func-timbre-cvae-il
start = 
end = 
time_elapsed = 
