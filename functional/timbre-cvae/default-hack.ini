[audio]
sample_rate = 44100 
hop_length = 128
bins_per_octave = 48
num_octaves = 8

#Fast Griffin-Lim - number of iterations
n_iter = 64

[dataset]

datapath = C:\Users\il\Desktop\ImmersiveLab\machine-learning\datasets\Electroacoustic-Roads
cqt_dataset = npy
workspace = 
run_number = 0

[CVAE]
latent_dim = 8

num_dense_layers = 3
dense_units = 2048
dense_unit_divider = 2

num_conv_layers = 0
num_inital_filters = 32
kernel_size = 3

kl_beta = 5e-5
batch_norm = False
output_activation = relu

[training]
epochs = 5000
learning_rate = 0.0001
batch_size = 256
buffer_size = 60000
buffer_size_dataset = True
continue_training = False

max_ckpts_to_keep = 2
checkpoint_epochs = 15
save_best_only = True
learning_schedule = False
early_patience_epoch = 100
early_delta = 1e-9

[notes]
additional_notes = testing a working model with longer run now. 

mynotes = testing-example-audio-writting

[extra]
normalize_examples = False
example_length = 15
plot_model = True
interpolations_audio_1 = 05 Sculptor.wav
audio_1_offset = 75
interpolations_audio_2 = 05 Sculptor.wav
audio_2_offset = 118
num_random_interpolations = 4
description = func-timbre-cvae-il
start = 
end = 
time_elapsed = 
